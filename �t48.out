04/20/2019 01:07:09 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
04/20/2019 01:07:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/wen062/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
04/20/2019 01:07:13 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/wen062/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
04/20/2019 01:07:13 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/wen062/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/wen062.23595610/tmp9txkj_2s
04/20/2019 01:07:17 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

04/20/2019 01:07:19 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
04/20/2019 01:07:19 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
04/20/2019 01:07:46 - INFO - __main__ -   ***** Running training *****
04/20/2019 01:07:46 - INFO - __main__ -     Num examples = 23925
04/20/2019 01:07:46 - INFO - __main__ -     Batch size = 32
04/20/2019 01:07:46 - INFO - __main__ -     Num steps = 37350
04/20/2019 01:07:50 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:50 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:50 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:50 - INFO - pytorch_pretrained_bert.modeling -   token classification
/apps/pytorch/1.0.0-py37-cuda92/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:52 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
04/20/2019 01:07:53 - INFO - pytorch_pretrained_bert.modeling -   token classification
Traceback (most recent call last):
  File "./run_bbn.py", line 885, in <module>
    main()
  File "./run_bbn.py", line 696, in main
    loss = model(input_ids, segment_ids, input_mask, label_ids)
  File "/apps/pytorch/1.0.0-py37-cuda92/lib/python3.7/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/apps/pytorch/1.0.0-py37-cuda92/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 143, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/apps/pytorch/1.0.0-py37-cuda92/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 153, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/apps/pytorch/1.0.0-py37-cuda92/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 83, in parallel_apply
    raise output
  File "/apps/pytorch/1.0.0-py37-cuda92/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 59, in _worker
    output = module(*input, **kwargs)
  File "/apps/pytorch/1.0.0-py37-cuda92/lib/python3.7/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/wen062/code/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py", line 1122, in forward
    active_logits = logits.view(-1, self.num_labels)[active_loss]
RuntimeError: copy_if failed to synchronize: device-side assert triggered
/flush3/hli001/installs/pytorch/pytorch-1.0.0-git/aten/src/THCUNN/ClassNLLCriterion.cu:105: void cunn_ClassNLLCriterion_updateOutput_kernel(Dtype *, Dtype *, Dtype *, long *, Dtype *, int, int, int, int, long) [with Dtype = float, Acctype = float]: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.
